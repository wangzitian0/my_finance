# GitHub CI/CD Workflows

Automated testing and deployment configuration for the SEC Filing-Enhanced Quantitative Trading Platform.

## ğŸ¯ Testing Architecture Overview

**Design Philosophy**: Fast, reliable validation using representative data samples

The entire testing system runs efficiently with minimal overhead:
- **Execution Time**: 2-5 minutes for complete validation
- **Test Scope**: Equivalent to local development testing (same as `p3 test f2`)
- **Data Quality**: Real SEC filings ensure realistic validation
- **CI Optimization**: All workflows designed for rapid feedback

## ğŸ§ª Testing System Components

### 1. Unit Tests âœ… (Required - Must Pass)
**Gate**: 100% pass rate - any failure blocks PR merge
**Validation**:
- Python syntax and import verification
- Type checking and code standards compliance
- Core functionality module testing
- Dependency validation

### 2. Local Development Integration Tests ğŸ“Š (Report Generation)
**Purpose**: End-to-end workflow validation with comprehensive reporting
**Process**:
- SEC data retrieval â†’ DCF model calculation â†’ output generation
- Database interaction testing (PostgreSQL, Neo4j, Redis, Vector DB)
- CLI functionality verification
- Data quality validation

**Output**: Comprehensive test reports generated for future quality review (LLM bot integration planned)

### 3. Test Coverage Gates ğŸ“ˆ (Implemented)
**Status**: Active (merged in previous PRs)
**Function**: Aggregate coverage statistics and quality thresholds across all test types

## ğŸ¤– AI-Powered Code Review

### Automatic Code Review
- **Trigger**: Every push to pull request
- **Scope**: Code quality, security, compliance, and best practices
- **Coverage**: General review focusing on system integrity

### Interactive AI Assistant
- **Trigger**: `@claude` mentions in issues/PRs  
- **Function**: Answer questions and provide development assistance
- **Usage**: Direct interaction for specific guidance

### Review Coverage
- Code quality and architectural consistency
- Security vulnerabilities and performance considerations
- Policy compliance validation
- Technical debt identification and suggestions

## ğŸ”„ Post-Merge Automation

### Automatic Issue Generation
**Trigger**: After successful merge to main branch
**Process**:
- Analyze merged changes for improvement opportunities
- Generate GitHub issues with proper linking and context
- Apply intelligent labeling and priority assignment
- Track technical debt and optimization opportunities

### Performance Monitoring
- Track test execution times and performance baselines
- Generate alerts on performance degradation
- Maintain development velocity through fast feedback

## ğŸ“‹ Active Workflow Summary

| Workflow | Trigger | Purpose | Status |
|----------|---------|---------|--------|
| **Tests** | Push/PR | Unit + Integration validation | âœ… Active |
| **Code Review** | PR creation/update | Automated AI code review | âœ… Active |
| **AI Assistant** | @claude mentions | Interactive development support | âœ… Active |
| **Post-Merge Analysis** | Merge to main | Automatic issue generation | âœ… Active |
| **Development Integration Tests** | PR validation | End-to-end integration test prerequisites | âœ… Active |

## ğŸ”§ Developer Usage Guide

### Standard Development Workflow
1. **Code Development** â†’ Local implementation and testing
2. **Create Pull Request** â†’ Automatic testing and AI review triggered  
3. **Address Feedback** â†’ Resolve issues and respond to review comments
4. **Merge to Main** â†’ Post-merge analysis generates follow-up improvement tasks

### Manual Operations
- **@claude [question]**: Get AI assistance on specific topics
- **[skip-review]**: Skip automatic code review (add to PR title)
- **[manual-review]**: Request manual review process

### Test Requirements
- **Unit Tests**: Must pass completely for PR approval
- **Integration Tests**: Generate reports for quality validation
- **Coverage Gates**: Automatically enforced quality thresholds

## ğŸ¯ Performance Standards

- **Complete Test Suite**: Under 5 minutes execution time
- **CI Reliability**: Over 95% success rate
- **Test Coverage**: Comprehensive across unit and integration layers  
- **Review Turnaround**: Under 2 hours from PR to review completion

## ğŸ› ï¸ Technical Implementation Notes

### Local Development Equivalence
The CI testing pipeline runs the equivalent of local development testing (`p3 test f2`), ensuring consistency between local and remote validation while optimizing for CI speed and reliability.

### Integration Test Evolution
Local Development Integration Tests (formerly M7 validation) focus on end-to-end workflow verification with comprehensive report generation. Future enhancements will include LLM bot quality review integration.

### Quality Assurance Framework
All testing components work together to maintain code quality, system reliability, and development velocity while preventing technical debt accumulation.

## ğŸ“š Related Documentation

- **Project Architecture**: `../README.md`
- **CLI Commands**: `../common/README.md` 
- **Company Policies**: `../CLAUDE.md`

## ğŸ†˜ Support

- **General Issues**: Create a GitHub issue
- **Development Questions**: Use `@claude` in issues/PRs
- **Urgent Matters**: Contact the development team directly