#!/usr/bin/env python3
"""
Create PR with mandatory M7 end-to-end testing
This script automates the complete PR creation workflow with M7 validation
"""

import argparse
import json
import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path


def run_command(cmd, description, timeout=None, check=True):
    """Run a command with proper error handling"""
    print(f"üîÑ {description}...")
    try:
        if isinstance(cmd, str):
            result = subprocess.run(
                cmd, shell=True, capture_output=True, text=True, timeout=timeout, check=check
            )
        else:
            result = subprocess.run(
                cmd, capture_output=True, text=True, timeout=timeout, check=check
            )

        if result.returncode == 0:
            print(f"‚úÖ {description} - SUCCESS")
            if result.stdout.strip():
                print(f"   Output: {result.stdout.strip()}")
            return result
        else:
            print(f"‚ùå {description} - FAILED")
            if result.stderr.strip():
                print(f"   Error: {result.stderr.strip()}")
            if check:
                sys.exit(1)
            return result
    except subprocess.TimeoutExpired:
        print(f"‚è∞ {description} - TIMEOUT ({timeout}s)")
        if check:
            sys.exit(1)
        return None
    except Exception as e:
        print(f"üí• {description} - EXCEPTION: {e}")
        if check:
            sys.exit(1)
        return None


def get_current_branch():
    """Get current git branch"""
    result = run_command("git branch --show-current", "Getting current branch")
    return result.stdout.strip()


def get_uncommitted_changes():
    """Check for uncommitted changes"""
    result = run_command("git status --porcelain", "Checking for uncommitted changes", check=False)
    return result.stdout.strip() if result else ""


def run_end_to_end_test():
    """Run M7 end-to-end test with DeepSeek 1.5b for speed"""
    print("\n" + "=" * 60)
    print("üß™ RUNNING MANDATORY END-TO-END TEST (FAST MODE)")
    print("üöÄ Using DeepSeek 1.5b model for accelerated testing")
    print("=" * 60)

    # Clean any existing build artifacts
    run_command(
        "rm -rf data/stage_99_build/build_*", "Cleaning existing build artifacts", check=False
    )
    run_command("rm -f common/latest_build", "Cleaning latest build symlink", check=False)

    # Start environment if needed (Python-based status)
    run_command(
        "./p3 status",
        "Checking environment status",
        check=False,
    )

    test_success = False
    try:
        # Verify DeepSeek 1.5b model is available
        print("üîç Verifying DeepSeek 1.5b model configuration...")
        print("   Config path will be: data/llm/configs/deepseek_fast.yml") 
        print("   Expected model: deepseek-r1:1.5b")
        
        # Build F2 dataset (faster test) using DeepSeek 1.5b model for PR validation
        print("üöÄ Starting fast-build with DeepSeek 1.5b - should NOT use gpt-oss:20b")
        run_command("./p3 fast-build f2", "Building F2 dataset with DeepSeek 1.5b", timeout=300)  # 5 minutes
        
        # Verify the model was actually used
        print("üîç Verifying model usage in connection logs...")
        run_command("tail -1 data/log/ollama_connection.json | grep -o 'deepseek-r1:1.5b' || echo 'WARNING: DeepSeek model not found in logs'", "Checking model selection", check=False)
        test_success = True
    except Exception as e:
        print(f"‚ö†Ô∏è  F2 build failed: {e}")
        print("üîç Checking if we can validate with existing data...")

        # Try to validate with existing data instead
        existing_files = 0
        for location in ["data/stage_00_original/yfinance", "data/stage_01_extract/yfinance"]:
            if Path(location).exists():
                result = run_command(
                    f"find {location} -name '*.json' -type f | wc -l",
                    f"Counting files in {location}",
                    check=False,
                )
                if result and result.stdout.strip():
                    count = int(result.stdout.strip())
                    existing_files += count
                    print(f"üìÅ Found {count} existing files in {location}")

        if existing_files >= 2:  # At least 1 file per F2 ticker
            print(f"‚úÖ Found {existing_files} existing data files - sufficient for validation")
            test_success = True
        else:
            print(f"‚ùå Only found {existing_files} files - insufficient for F2 validation")
            return False

    # Validate build results
    build_status = run_command(
        "./p3 build-status",
        "Checking build status",
    )

    # Check for expected files in multiple possible locations
    file_locations = ["data/stage_01_extract/yfinance", "data/stage_00_original/yfinance", "latest"]

    total_files = 0
    for location in file_locations:
        if Path(location).exists():
            location_files = run_command(
                f"find {location} -name '*.json' -type f | wc -l",
                f"Counting files in {location}",
                check=False,
            )
            if location_files and location_files.stdout.strip():
                count = int(location_files.stdout.strip())
                total_files += count
                print(f"üìÅ Found {count} files in {location}")

    print(f"üìä Total M7 data files found: {total_files}")

    if total_files < 7:  # At least 1 file per M7 ticker
        print(f"‚ùå FAIL: Expected at least 7 M7 files (one per ticker), found {total_files}")
        print("üîç Build artifacts preserved for debugging")
        return False
    elif total_files < 21:  # Ideal: 7 tickers √ó 3 periods = 21 files
        print(f"‚ö†Ô∏è  WARNING: Expected 21 M7 files (7 tickers √ó 3 periods), found {total_files}")
        print("   This may be acceptable if some data sources are unavailable")

    if total_files == 0:
        print("‚ùå No M7 data files found")
        print("üîç Build artifacts preserved for debugging")
        return False

    # Test passed - build artifacts remain in data/build/ (gitignored)
    print("‚úÖ END-TO-END TEST PASSED")
    print("üì¶ Build artifacts remain in data/build/ (gitignored)")

    print("‚úÖ Git status is clean - ready for PR creation!")
    return total_files  # Return file count for test validation


def create_test_marker(file_count: int):
    """Create test validation information for commit message"""
    import socket
    from datetime import datetime, timezone

    # Get current commit hash
    commit_result = run_command("git rev-parse HEAD", "Getting commit hash", check=False)
    commit_hash = commit_result.stdout.strip() if commit_result else "unknown"

    # Create test validation data to be embedded in commit message
    test_info = {
        "timestamp": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
        "host": socket.gethostname(),
        "companies": 7,
        "data_files": file_count,
        "commit_hash": commit_hash,
        "validation_passed": True,
    }

    print("üìù Created M7 test validation info for commit message")
    return test_info


def create_pr_workflow(title, issue_number, description_file=None, skip_m7_test=False):
    """Complete PR creation workflow"""

    print("\n" + "=" * 60)
    print("üöÄ STARTING PR CREATION WORKFLOW")
    print("=" * 60)

    # 1. Check current state
    current_branch = get_current_branch()
    print(f"üìç Current branch: {current_branch}")

    if current_branch == "main":
        print("‚ùå Cannot create PR from main branch")
        sys.exit(1)

    uncommitted = get_uncommitted_changes()
    if uncommitted:
        print("‚ùå Uncommitted changes detected:")
        print(uncommitted)
        print("Please commit or stash changes first")
        sys.exit(1)

    # 2.5. CRITICAL: Sync with latest main and rebase
    print("\nüîÑ Syncing with latest main branch...")
    run_command("git fetch origin main", "Fetching latest main")

    # Check if current branch is behind main
    behind_check = run_command(
        "git log --oneline HEAD..origin/main", "Checking if branch is behind main", check=False
    )
    if behind_check and behind_check.stdout.strip():
        commits_behind = len(behind_check.stdout.strip().split("\n"))
        print(f"‚ö†Ô∏è  Current branch is {commits_behind} commits behind origin/main")

        # Rebase onto latest main
        print("üîÑ Rebasing onto latest origin/main...")
        run_command("git rebase origin/main", "Rebasing onto origin/main")

        # Data is now part of main repository, no separate handling needed
        print("‚ÑπÔ∏è  Data directory is integrated in main repository")

        print("‚úÖ Rebase completed - branch is now up to date")
    else:
        print("‚úÖ Branch is already up to date with origin/main")

    # 2.9. MANDATORY: Format code before testing
    print("\nüîÑ Running code formatting...")
    run_command("./p3 format", "Formatting Python code with black and isort")

    # Check if formatting made changes
    uncommitted_after_format = get_uncommitted_changes()
    if uncommitted_after_format:
        print("üìù Code formatting made changes - committing them...")
        run_command("git add .", "Adding formatted code changes")
        run_command(
            'git commit -m "Format code with black and isort\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>"',
            "Committing formatted code",
        )
        print("‚úÖ Formatted code committed")
    else:
        print("‚úÖ Code already properly formatted")

    # 3. MANDATORY: Run M7 end-to-end test (unless explicitly skipped)
    test_info = None
    if not skip_m7_test:
        test_result = run_end_to_end_test()
        if isinstance(test_result, int) and test_result > 0:
            # Test passed, create test validation info
            test_info = create_test_marker(test_result)
        else:
            print("‚ùå M7 test failed - PR creation aborted")
            sys.exit(1)
    else:
        print("‚ö†Ô∏è  SKIPPING M7 TEST - NOT RECOMMENDED")

    # 4. Handle data directory changes (now part of main repository)
    print("\nüîÑ Handling data directory changes...")
    run_command("./p3 commit-data-changes", "Staging data directory changes")

    # 4.5. Ask about promoting build to release before creating PR
    ask_about_build_release()

    # 5. Update commit message with M7 test info (no marker file needed)
    if test_info:
        # Update commit message to include M7 test info
        current_commit = run_command("git log -1 --pretty=%B", "Getting current commit message")
        original_msg = current_commit.stdout.strip()

        # Add M7 test validation to commit message
        updated_msg = f"""{original_msg}

‚úÖ M7-TESTED: This commit passed M7 end-to-end testing
üìä Test Results: {test_info['data_files']} data files validated
üïê Test Time: {test_info['timestamp']}
üîç Test Host: {test_info['host']}
üìù Commit Hash: {test_info['commit_hash']}"""

        # Amend commit with test validation info
        run_command(f'git commit --amend -m "{updated_msg}"', "Updating commit with M7 test info")
        print("üìù M7 test validation included in commit message - no marker file needed")

    # 6. Push current branch (handle potential conflicts)
    print(f"üîÑ Pushing branch {current_branch}...")
    try:
        push_result = run_command(
            f"git push -u origin {current_branch}", f"Pushing branch {current_branch}", check=False
        )
        if push_result and push_result.returncode != 0:
            if "non-fast-forward" in push_result.stderr or "rejected" in push_result.stderr:
                print("‚ö†Ô∏è  Remote branch has diverged. Attempting to resolve...")
                # Fetch and rebase
                run_command("git fetch origin", "Fetching latest changes")
                rebase_result = run_command(
                    f"git rebase origin/{current_branch}", "Rebasing on remote changes", check=False
                )
                if rebase_result and rebase_result.returncode == 0:
                    # Try push again after rebase
                    run_command(
                        f"git push origin {current_branch}",
                        f"Pushing rebased branch {current_branch}",
                    )
                else:
                    print("‚ùå Rebase failed. Using force-with-lease for safety...")
                    run_command(
                        f"git push --force-with-lease origin {current_branch}",
                        f"Force pushing branch {current_branch}",
                    )
            else:
                print(f"‚ùå Push failed with error: {push_result.stderr}")
                sys.exit(1)
        else:
            print(f"‚úÖ Successfully pushed {current_branch}")
    except Exception as e:
        print(f"‚ùå Push failed with exception: {e}")
        sys.exit(1)

    # 7. Create PR body
    if description_file and Path(description_file).exists():
        with open(description_file, "r") as f:
            body = f.read()
    else:
        # Generate default PR body
        body = f"""## Summary

[Describe your changes here]

## Key Changes

- [Change 1]
- [Change 2] 
- [Change 3]

## Test Results

‚úÖ **M7 End-to-End Test**: PASSED
- M7 dataset built successfully
- All expected data files generated
- Build tracking verified

## Test Plan

- [x] M7 end-to-end test passed
- [x] Data directory changes staged
- [ ] Additional testing as needed

Fixes #{issue_number}

ü§ñ Generated with [Claude Code](https://claude.ai/code)"""

    # 8. Create or update PR using gh CLI
    # First check if PR already exists
    existing_pr_result = run_command(
        f"gh pr list --head {current_branch} --json url,number --jq '.[0]'",
        "Checking for existing PR",
        check=False,
    )

    existing_pr_url = None
    if (
        existing_pr_result
        and existing_pr_result.stdout.strip()
        and existing_pr_result.stdout.strip() != "null"
    ):
        try:
            existing_pr_data = json.loads(existing_pr_result.stdout.strip())
            if existing_pr_data and "url" in existing_pr_data:
                existing_pr_url = existing_pr_data["url"]
                pr_number = existing_pr_data["number"]
                print(f"üìù Found existing PR #{pr_number}: {existing_pr_url}")

                # Update existing PR
                result = run_command(
                    f'gh pr edit {pr_number} --title "{title}" --body "{body}"',
                    "Updating existing PR",
                )
        except (json.JSONDecodeError, KeyError):
            pass

    if not existing_pr_url:
        # Create new PR
        result = run_command(f'gh pr create --title "{title}" --body "{body}"', "Creating new PR")

    # Extract PR URL from output or use existing PR URL
    pr_url = existing_pr_url
    if not pr_url and result:
        # Check stdout first (where gh pr create normally outputs the URL)
        if result.stdout:
            lines = result.stdout.split("\n")
            for line in lines:
                if "https://github.com/" in line and "/pull/" in line:
                    pr_url = line.strip()
                    break

        # Fallback to stderr if not found in stdout
        if not pr_url and result.stderr:
            lines = result.stderr.split("\n")
            for line in lines:
                if "https://github.com/" in line and "/pull/" in line:
                    pr_url = line.strip()
                    break

    if not pr_url:
        print("‚ö†Ô∏è  Could not extract PR URL from gh output")
        if result and result.stdout:
            print(f"   stdout: {result.stdout.strip()}")
        if result and result.stderr:
            print(f"   stderr: {result.stderr.strip()}")
        # Try to get PR URL using gh pr list as fallback
        print("üîÑ Attempting to find PR URL using gh pr list...")
        fallback_result = run_command(
            f"gh pr list --head {current_branch} --json url --jq '.[0].url'",
            "Getting PR URL from list",
            check=False,
        )
        if fallback_result and fallback_result.stdout.strip():
            pr_url = fallback_result.stdout.strip()
            print(f"‚úÖ Found PR URL via fallback: {pr_url}")
        else:
            print("‚ùå Could not determine PR URL")
            return None

    if existing_pr_url:
        print(f"‚úÖ PR Updated: {pr_url}")
    else:
        print(f"‚úÖ PR Created: {pr_url}")

    # 9. Update commit message with actual PR URL
    pr_number = pr_url.split("/pull/")[-1]

    # Get the last commit message
    last_commit = run_command("git log -1 --pretty=%B", "Getting last commit message")
    commit_msg = last_commit.stdout.strip()

    # Update PR placeholder with actual number
    if "PLACEHOLDER" in commit_msg:
        updated_msg = commit_msg.replace("PLACEHOLDER", pr_number)
    elif f"#{issue_number}" in commit_msg and "PR:" not in commit_msg:
        # Add PR line if missing
        lines = commit_msg.split("\n")
        for i, line in enumerate(lines):
            if f"#{issue_number}" in line:
                lines.insert(i + 1, "")
                lines.insert(i + 2, f"PR: {pr_url}")
                break
        updated_msg = "\n".join(lines)
    else:
        updated_msg = commit_msg

    # Amend commit with updated message
    run_command(f'git commit --amend -m "{updated_msg}"', "Updating commit with PR URL")
    run_command("git push --force-with-lease", "Force pushing updated commit")

    print("\n" + "=" * 60)
    print("üéâ PR CREATION WORKFLOW COMPLETED")
    print("=" * 60)
    print(f"üìã PR Title: {title}")
    print(f"üîó PR URL: {pr_url}")
    print(f"üè∑Ô∏è  Issue: #{issue_number}")
    print(f"üåø Branch: {current_branch}")
    print("‚úÖ M7 test passed before PR creation")
    print("‚úÖ Data directory changes staged")
    print("‚úÖ Commit message updated with PR URL")

    return pr_url


def ask_about_build_release():
    """Ask user if they want to promote the latest build to release"""
    print("\n" + "=" * 60)
    print("üì¶ BUILD RELEASE MANAGEMENT")
    print("=" * 60)

    # Check if there are any builds to release
    from pathlib import Path

    # Ensure we're working from project root
    project_root = Path(__file__).parent.parent
    build_dir = project_root / "data" / "build"

    if not build_dir.exists():
        print("‚ÑπÔ∏è  No builds found to release")
        return

    # Find the latest build
    build_dirs = [d for d in build_dir.iterdir() if d.is_dir() and d.name.startswith("build_")]
    if not build_dirs:
        print("‚ÑπÔ∏è  No builds found to release")
        return

    latest_build = max(build_dirs, key=lambda d: d.name)
    build_id = latest_build.name.replace("build_", "")

    print(f"üîç Found latest build: {build_id}")

    # Check build contents
    artifacts = []
    if (latest_build / "BUILD_MANIFEST.md").exists():
        artifacts.append("Build manifest")
    if any(latest_build.glob("**/*.txt")):
        artifacts.append("DCF reports")
    if any(latest_build.glob("**/*.json")):
        artifacts.append("Data files")

    if artifacts:
        print(f"üìä Build contains: {', '.join(artifacts)}")

        try:
            response = (
                input("\n‚ùì Would you like to promote this build to data/release/? [y/N]: ")
                .strip()
                .lower()
            )
            if response in ["y", "yes"]:
                promote_build_to_release(build_id, str(latest_build))
            else:
                print("‚è≠Ô∏è  Skipped build promotion")
        except (KeyboardInterrupt, EOFError):
            print("\n‚è≠Ô∏è  Skipped build promotion")
    else:
        print("‚ö†Ô∏è  Build appears to be empty or incomplete")


def promote_build_to_release(build_id: str, build_path: str):
    """Promote a build to the release directory"""
    import shutil
    from datetime import datetime
    from pathlib import Path

    print(f"\nüöÄ Promoting build {build_id} to release...")

    # Ensure we're working from project root
    project_root = Path(__file__).parent.parent
    release_dir = project_root / "data" / "release"
    release_dir.mkdir(exist_ok=True)

    # Create release directory with timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    release_path = release_dir / f"release_{timestamp}_build_{build_id}"

    try:
        # Copy build to release directory
        shutil.copytree(build_path, release_path)

        # Create release notes
        release_notes = f"""# Release {timestamp}

## Build Information
- **Build ID**: {build_id}
- **Release Date**: {datetime.now().isoformat()}
- **Source**: build_{build_id}

## Contents
- Build manifest and logs
- DCF analysis results
- Data processing artifacts

## Validation Status
‚úÖ M7 end-to-end testing passed
‚úÖ Build completed successfully

Generated by PR workflow automation.
"""

        with open(release_path / "RELEASE_NOTES.md", "w") as f:
            f.write(release_notes)

        print(f"‚úÖ Build promoted to: data/release/release_{timestamp}_build_{build_id}/")
        print("üìù Release notes created")
        print("‚ö†Ô∏è  Remember to commit the release directory changes to git!")

        # Commit release to git
        try:
            run_command("git add data/release/", "Adding release to git")
            commit_msg = f"""Add release {timestamp} from build {build_id}

ü§ñ Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude <noreply@anthropic.com>"""
            run_command(f'git commit -m "{commit_msg}"', "Committing release")
            print("‚úÖ Release committed to git")
        except Exception as commit_error:
            print(f"‚ö†Ô∏è  Failed to commit release: {commit_error}")
            print("   You can manually commit with: git add data/release/ && git commit")

    except Exception as e:
        print(f"‚ùå Failed to promote build: {e}")
        return


def main():
    """Main CLI interface"""
    parser = argparse.ArgumentParser(
        description="Create PR with mandatory M7 end-to-end testing",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python infra/create_pr_with_m7_test.py "Fix config bug" 42
  python infra/create_pr_with_m7_test.py "Add new feature" 43 --description pr_body.md
        """,
    )

    parser.add_argument("title", nargs="?", help="PR title")
    parser.add_argument("issue_number", nargs="?", type=int, help="GitHub issue number")
    parser.add_argument("--description", help="Path to file containing PR description")
    parser.add_argument(
        "--skip-m7-test", action="store_true", help="Skip M7 test (NOT RECOMMENDED)"
    )
    parser.add_argument(
        "--skip-pr-creation", action="store_true", help="Only run M7 test, skip PR creation"
    )

    args = parser.parse_args()

    if args.skip_pr_creation:
        # Only run M7 test
        success = run_end_to_end_test()
        sys.exit(0 if success else 1)

    # Validate required arguments for PR creation
    if not args.title or not args.issue_number:
        parser.error("title and issue_number are required when creating PR")

    if args.skip_m7_test:
        print("‚ö†Ô∏è  WARNING: Skipping M7 test - this is NOT recommended!")
        time.sleep(3)

    try:
        pr_url = create_pr_workflow(
            args.title, args.issue_number, args.description, args.skip_m7_test
        )

        if pr_url:
            print(f"\nüöÄ PR successfully created: {pr_url}")
            sys.exit(0)
        else:
            print("\n‚ùå PR creation failed")
            sys.exit(1)

    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  PR creation cancelled by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nüí• Unexpected error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
