# Default LLM Configuration for Production DCF Analysis
# Balanced settings for accuracy and performance

llm_service:
  provider: "ollama"
  base_url: "http://localhost:11434"
  model: "llama3.1:8b"
  timeout: 300
  max_retries: 3

generation:
  temperature: 0.7
  max_tokens: 4096
  stream: false
  seed: null

# Standard DCF generation settings
dcf_generation:
  max_companies_per_batch: 10
  enable_sec_integration: true
  enable_semantic_retrieval: true
  debug_mode: false
  fast_mode: false
  
# Full context retrieval
semantic_retrieval:
  similarity_threshold: 0.8
  max_results: 5
  enable_context_compression: false

# Comprehensive reporting
reporting:
  bilingual: true
  include_charts: true
  include_detailed_analysis: true
  format: "markdown"

# Standard performance settings
performance:
  enable_caching: true
  parallel_processing: true
  batch_size: 5
  
# Detailed logging
logging:
  level: "INFO"
  log_llm_requests: true
  log_responses: true
  save_intermediate_results: true

# FinLang embedding configuration
finlang_embedding:
  model_name: "FinLang/finance-embeddings-investopedia"
  enable_semantic_search: true
  cache_embeddings: true

# Ollama specific settings
ollama:
  keep_alive: "5m"
  num_predict: -1
  repeat_penalty: 1.1